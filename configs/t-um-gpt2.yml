classifier_name: t-um-gpt2
classifier_loss_fn: dice
classifier_learning_rate: 0.00005
classifier_weight_decay: 0.1
classifier_warmup_steps: 500 # @ ~15% => 9989 (examples) / 32 (batch) = 313 (step) x 10 (epochs) = 3130 steps
classifier_metric_for_best_model: f1_weighted
classifier_early_stopping_patience: 5
classifier_classes:
  - anger
  - disgust
  - fear
  - joy
  - neutral
  - sadness
  - surprise

modules_text_encoder: gpt2
modules_visual_encoder: none
modules_audio_encoder: none
modules_fusion: concat

text_in_features: -1 # defined by tokenizer & padding
text_out_features: -1 # defined by the encoder output hidden state

feedforward_layers:
  - out_features: 256
    dropout: 0.2
