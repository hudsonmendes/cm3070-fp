{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CM3070, Final Project\n",
    "\n",
    "```\n",
    "University of London\n",
    "BSc Computer Science\n",
    "CM3070, Final Project\n",
    "Hudson Leonardo MENDES\n",
    "hlm12@student.london.ac.uk\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Domain-specific Area\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Dataset\n",
    "\n",
    "**Multimodal EmotionLines Dataset(MELD)**[2, 3]\n",
    "\n",
    "> Multimodal EmotionLines Dataset (MELD) has been created by enhancing and extending EmotionLines dataset. MELD contains the same dialogue instances available in EmotionLines, but it also encompasses audio and visual modality along with text. MELD has more than 1400 dialogues and 13000 utterances from Friends TV series. Multiple speakers participated in the dialogues. Each utterance in a dialogue has been labeled by any of these seven emotions -- Anger, Disgust, Sadness, Joy, Neutral, Surprise and Fear. MELD also has sentiment (positive, negative and neutral) annotation for each utterance.\n",
    "> (Hakim, 2021)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Objective\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T14:43:02.985547Z",
     "start_time": "2023-07-13T14:43:02.842918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[metadata]\n",
      "name = hlm12erc\n",
      "version = attr: hlm12erc.VERSION\n",
      "author = Hudson Mendes\n",
      "author_email = hlm12@student.london.ac.uk\n",
      "description = Final Project from University of London\n",
      "long_description = file: README.md, LICENSE\n",
      "keywords = university-of-london\n",
      "license = copyright\n",
      "\n",
      "[options]\n",
      "zip_safe = False\n",
      "include_package_data = True\n",
      "packages = find:\n",
      "package_dir =\n",
      "    =src\n",
      "python_requires = >=3.10\n",
      "install_requires =\n",
      "    torch>=2.0.1\n",
      "    transformers>=4.30.2\n",
      "\n",
      "[options.package_data]\n",
      "\n",
      "[options.extras_require]\n",
      "# development\n",
      "dev =\n",
      "    pre-commit>=3.3.3\n",
      "    black[jupyter]>=23.7.0\n",
      "    isort>=5.12.0\n",
      "\n",
      "test =\n",
      "    pytest>=7.4.0\n",
      "\n",
      "# mlops\n",
      "etl =\n",
      "    kaggle>=1.5.13\n",
      "    tqdm>=4.65.0\n",
      "    pandas>=2.0.1\n",
      "    google-cloud-storage>=2.10.0\n",
      "    moviepy>=1.0.3\n",
      "    Pillow>=10.0.0\n",
      "\n",
      "modeling =\n",
      "    # no dependencies yet\n",
      "\n",
      "training =\n",
      "    # no dependencies yet\n",
      "\n",
      "serving =\n",
      "    fire>=0.5.0\n",
      "\n",
      "all =\n",
      "    %(dev)s\n",
      "    %(test)s\n",
      "    %(etl)s\n",
      "    %(modeling)s\n",
      "    %(training)s\n",
      "    %(serving)s\n",
      "\n",
      "[options.packages.find]\n",
      "include =\n",
      "    ./src\n"
     ]
    }
   ],
   "source": [
    "!cat ../setup.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T14:43:03.141254Z",
     "start_time": "2023-07-13T14:43:03.092297Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T14:43:03.487527Z",
     "start_time": "2023-07-13T14:43:03.452824Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Paths & Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T14:43:03.870117Z",
     "start_time": "2023-07-13T14:43:03.837574Z"
    }
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "dir_data = pathlib.Path(\"../data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Data Extraction, Transformation & Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T14:43:07.117036Z",
     "start_time": "2023-07-13T14:43:04.961415Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -e '.[etl]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T14:46:22.459843Z",
     "start_time": "2023-07-13T14:46:21.635307Z"
    }
   },
   "outputs": [],
   "source": [
    "from hlm12erc.etl import ETL, KaggleDataset\n",
    "\n",
    "ETL(\n",
    "    dataset=KaggleDataset(\n",
    "        owner=\"zaber666\",\n",
    "        name=\"meld-dataset\",\n",
    "        subdir=\"MELD-RAW/MELD.Raw\",\n",
    "    )\n",
    ").into(\n",
    "    uri_or_folderpath=dir_data,\n",
    "    force=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {str(dir_data)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>sequence</th>\n",
       "      <th>x_text</th>\n",
       "      <th>x_visual</th>\n",
       "      <th>x_audio</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>also I was the point person on my companys tr...</td>\n",
       "      <td>d-0-seq-0.png</td>\n",
       "      <td>d-0-seq-0.wav</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>You mustve had your hands full.</td>\n",
       "      <td>d-0-seq-1.png</td>\n",
       "      <td>d-0-seq-1.wav</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>That I did. That I did.</td>\n",
       "      <td>d-0-seq-2.png</td>\n",
       "      <td>d-0-seq-2.wav</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>So lets talk a little bit about your duties.</td>\n",
       "      <td>d-0-seq-3.png</td>\n",
       "      <td>d-0-seq-3.wav</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>My duties?  All right.</td>\n",
       "      <td>d-0-seq-4.png</td>\n",
       "      <td>d-0-seq-4.wav</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>9984</td>\n",
       "      <td>1038</td>\n",
       "      <td>13</td>\n",
       "      <td>You or me?</td>\n",
       "      <td>d-1038-seq-13.png</td>\n",
       "      <td>d-1038-seq-13.wav</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>9985</td>\n",
       "      <td>1038</td>\n",
       "      <td>14</td>\n",
       "      <td>I got it. Uh, Joey, women don't have Adam's ap...</td>\n",
       "      <td>d-1038-seq-14.png</td>\n",
       "      <td>d-1038-seq-14.wav</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>9986</td>\n",
       "      <td>1038</td>\n",
       "      <td>15</td>\n",
       "      <td>You guys are messing with me, right?</td>\n",
       "      <td>d-1038-seq-15.png</td>\n",
       "      <td>d-1038-seq-15.wav</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>9987</td>\n",
       "      <td>1038</td>\n",
       "      <td>16</td>\n",
       "      <td>Yeah.</td>\n",
       "      <td>d-1038-seq-16.png</td>\n",
       "      <td>d-1038-seq-16.wav</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>9988</td>\n",
       "      <td>1038</td>\n",
       "      <td>17</td>\n",
       "      <td>That was a good one. For a second there, I was...</td>\n",
       "      <td>d-1038-seq-17.png</td>\n",
       "      <td>d-1038-seq-17.wav</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9989 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  dialogue  sequence  \\\n",
       "0              0         0         0   \n",
       "1              1         0         1   \n",
       "2              2         0         2   \n",
       "3              3         0         3   \n",
       "4              4         0         4   \n",
       "...          ...       ...       ...   \n",
       "9984        9984      1038        13   \n",
       "9985        9985      1038        14   \n",
       "9986        9986      1038        15   \n",
       "9987        9987      1038        16   \n",
       "9988        9988      1038        17   \n",
       "\n",
       "                                                 x_text           x_visual  \\\n",
       "0     also I was the point person on my companys tr...      d-0-seq-0.png   \n",
       "1                      You mustve had your hands full.      d-0-seq-1.png   \n",
       "2                               That I did. That I did.      d-0-seq-2.png   \n",
       "3         So lets talk a little bit about your duties.      d-0-seq-3.png   \n",
       "4                                My duties?  All right.      d-0-seq-4.png   \n",
       "...                                                 ...                ...   \n",
       "9984                                         You or me?  d-1038-seq-13.png   \n",
       "9985  I got it. Uh, Joey, women don't have Adam's ap...  d-1038-seq-14.png   \n",
       "9986               You guys are messing with me, right?  d-1038-seq-15.png   \n",
       "9987                                              Yeah.  d-1038-seq-16.png   \n",
       "9988  That was a good one. For a second there, I was...  d-1038-seq-17.png   \n",
       "\n",
       "                x_audio     label  \n",
       "0         d-0-seq-0.wav   neutral  \n",
       "1         d-0-seq-1.wav   neutral  \n",
       "2         d-0-seq-2.wav   neutral  \n",
       "3         d-0-seq-3.wav   neutral  \n",
       "4         d-0-seq-4.wav  surprise  \n",
       "...                 ...       ...  \n",
       "9984  d-1038-seq-13.wav   neutral  \n",
       "9985  d-1038-seq-14.wav   neutral  \n",
       "9986  d-1038-seq-15.wav  surprise  \n",
       "9987  d-1038-seq-16.wav   neutral  \n",
       "9988  d-1038-seq-17.wav       joy  \n",
       "\n",
       "[9989 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(dir_data / \"train.csv\")\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Statistical Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1. Measures of Spread\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "measures of spread:   0%|          | 0/9989 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "measures of spread: 100%|██████████| 9989/9989 [13:31<00:00, 12.30it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.2706, 0.2010, 0.1914]), tensor([0.1857, 0.1608, 0.1667]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def calculate_measures_of_spread(filenames: pd.Series) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Calculate the mean and standard deviation of the images in the training set.\n",
    "    This is required for image normalisation during training & inference.\n",
    "\n",
    "    :param filenames: The filenames of the images in the training set.\n",
    "    :return: The mean and standard deviation of the images in the training set.\n",
    "    \"\"\"\n",
    "    mean = torch.zeros(3)\n",
    "    std = torch.zeros(3)\n",
    "    transform = torchvision.transforms.ToTensor()\n",
    "    for filename in tqdm(filenames, desc=\"measures of spread\"):\n",
    "        filepath = dir_data / filename\n",
    "        tensor = transform(Image.open(filepath))\n",
    "        mean += tensor.mean(dim=(1, 2))\n",
    "        std += tensor.std(dim=(1, 2))\n",
    "    mean /= len(df_train.x_visual)\n",
    "    std /= len(df_train.x_visual)\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "calculate_measures_of_spread(filenames=df_train.x_visual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2. Types of Distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Data Visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1. Word Cloud & Frequency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2. Image Grid & Scatter Plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.3. Audio Feature Plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Machine Learning\n",
    "\n",
    "**Universal Machine-learning Workflow**[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Problem Definition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Measure of Success\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Evaluation Protocol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Data Preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Baseline Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hlm12erc.modelling import ERCModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6. Overfitting Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7. Model Tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Chollet, François. Deep Learning with Python. Manning, 2017.\n",
    "\n",
    "[2] Poria, Soujanya, et al. ‘MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversations’. ArXiv [Cs.CL], 2019, http://arxiv.org/abs/1810.02508. arXiv.\n",
    "\n",
    "[3] Chen, Sheng-Yeh, et al. ‘EmotionLines: An Emotion Corpus of Multi-Party Conversations’. ArXiv [Cs.CL], 2018, http://arxiv.org/abs/1802.08379. arXiv.\n",
    "\n",
    "[4] Su, Lin, et al. ‘GEM: A General Evaluation Benchmark for Multimodal Tasks’. ArXiv [Cs.CL], 2021, http://arxiv.org/abs/2106.09889. arXiv.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
