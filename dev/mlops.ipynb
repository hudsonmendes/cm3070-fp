{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CM3070, Final Project\n",
    "\n",
    "```\n",
    "University of London\n",
    "BSc Computer Science\n",
    "CM3070, Final Project\n",
    "Hudson Leonardo MENDES\n",
    "hlm12@student.london.ac.uk\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Domain-specific Area\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Dataset\n",
    "\n",
    "**Multimodal EmotionLines Dataset(MELD)**[2, 3]\n",
    "\n",
    "> Multimodal EmotionLines Dataset (MELD) has been created by enhancing and extending EmotionLines dataset. MELD contains the same dialogue instances available in EmotionLines, but it also encompasses audio and visual modality along with text. MELD has more than 1400 dialogues and 13000 utterances from Friends TV series. Multiple speakers participated in the dialogues. Each utterance in a dialogue has been labeled by any of these seven emotions -- Anger, Disgust, Sadness, Joy, Neutral, Surprise and Fear. MELD also has sentiment (positive, negative and neutral) annotation for each utterance.\n",
    "> (Hakim, 2021)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Objective\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T14:36:53.889336Z",
     "start_time": "2023-07-13T14:36:53.723985Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[metadata]\r\n",
      "name = hlm12erc\r\n",
      "version = attr: hlm12erc.VERSION\r\n",
      "author = Hudson Mendes\r\n",
      "author_email = hlm12@student.london.ac.uk\r\n",
      "description = Final Project from University of London\r\n",
      "long_description = file: README.md, LICENSE\r\n",
      "keywords = university-of-london\r\n",
      "license = copyright\r\n",
      "\r\n",
      "[options]\r\n",
      "zip_safe = False\r\n",
      "include_package_data = True\r\n",
      "packages = find:\r\n",
      "package_dir =\r\n",
      "    =src\r\n",
      "python_requires = >=3.10\r\n",
      "install_requires =\r\n",
      "    torch>=2.0.1\r\n",
      "    transformers>=4.30.2\r\n",
      "\r\n",
      "[options.package_data]\r\n",
      "\r\n",
      "[options.extras_require]\r\n",
      "# development\r\n",
      "dev =\r\n",
      "    pre-commit>=3.3.3\r\n",
      "    black[jupyter]>=23.7.0\r\n",
      "    isort>=5.12.0\r\n",
      "\r\n",
      "test =\r\n",
      "    pytest>=7.4.0\r\n",
      "\r\n",
      "# mlops\r\n",
      "etl =\r\n",
      "    kaggle>=1.5.13\r\n",
      "    tqdm>=4.65.0\r\n",
      "    pandas>=2.0.1\r\n",
      "    google-cloud-storage>=2.10.0\r\n",
      "    moviepy>=1.0.3\r\n",
      "    Pillow>=10.0.0\r\n",
      "\r\n",
      "modeling =\r\n",
      "    # no dependencies yet\r\n",
      "\r\n",
      "training =\r\n",
      "    # no dependencies yet\r\n",
      "\r\n",
      "serving =\r\n",
      "    fire>=0.5.0\r\n",
      "\r\n",
      "all =\r\n",
      "    %(dev)s\r\n",
      "    %(test)s\r\n",
      "    %(etl)s\r\n",
      "    %(modeling)s\r\n",
      "    %(training)s\r\n",
      "    %(serving)s\r\n",
      "\r\n",
      "[options.packages.find]\r\n",
      "include =\r\n",
      "    ./src\r\n"
     ]
    }
   ],
   "source": [
    "!cat ../setup.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T14:36:56.427301Z",
     "start_time": "2023-07-13T14:36:56.384190Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T14:36:56.940072Z",
     "start_time": "2023-07-13T14:36:56.909204Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Paths & Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T14:36:58.003023Z",
     "start_time": "2023-07-13T14:36:57.978251Z"
    }
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "dir_data = pathlib.Path(\"../data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Data Extraction, Transformation & Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T14:37:00.934564Z",
     "start_time": "2023-07-13T14:36:59.898531Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -e '.[etl]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1. [E]xtraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T14:40:15.567309Z",
     "start_time": "2023-07-13T14:37:03.849419Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hlm12erc.etl:Kaggle dataset: zaber666-meld-dataset\n",
      "INFO:hlm12erc.etl:Workspace set to: None\n",
      "INFO:hlm12erc.etl:Extracting dataset into: /tmp/hlm12erc/etl/zaber666-meld-dataset/extracted\n",
      "INFO:hlm12erc.etl.extraction:Downloading dataset into: /tmp/hlm12erc/etl/zaber666-meld-dataset/extractor/zaber666-meld-dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading meld-dataset.zip to /tmp/hlm12erc/etl/zaber666-meld-dataset/extractor/zaber666-meld-dataset\n",
      "... resuming from 6937378816 bytes (4867283296 bytes left) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                          | 9.19G/11.0G [03:08<02:04, 15.6MB/s]\n",
      "INFO:hlm12erc.etl.extraction:Extracting dataset into: /tmp/hlm12erc/etl/zaber666-meld-dataset/extracted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: '/tmp/hlm12erc/etl/zaber666-meld-dataset/extractor/zaber666-meld-dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhlm12erc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01metl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ETL, KaggleDataset\n\u001b[1;32m      3\u001b[0m ds_kaggle \u001b[38;5;241m=\u001b[39m KaggleDataset(owner\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzaber666\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeld-dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, subdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMELD-RAW/MELD.Raw\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m etl \u001b[38;5;241m=\u001b[39m \u001b[43mETL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds_kaggle\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minto\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri_or_folderpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdir_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Workspaces/hudsonmendes-estudos/cm3070-fp/src/hlm12erc/etl/__init__.py:63\u001b[0m, in \u001b[0;36mETL.into\u001b[0;34m(self, uri_or_folderpath)\u001b[0m\n\u001b[1;32m     61\u001b[0m loaded \u001b[38;5;241m=\u001b[39m uri_or_folderpath\n\u001b[1;32m     62\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting dataset into: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextracted\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 63\u001b[0m \u001b[43mKaggleDataExtractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkspace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextracted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransforming dataset into: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtransformed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     65\u001b[0m RawTo1NFTransformer(src\u001b[38;5;241m=\u001b[39mextracted, workspace\u001b[38;5;241m=\u001b[39mroot)\u001b[38;5;241m.\u001b[39mtransform(dest\u001b[38;5;241m=\u001b[39mtransformed)\n",
      "File \u001b[0;32m~/Workspaces/hudsonmendes-estudos/cm3070-fp/src/hlm12erc/etl/extraction.py:47\u001b[0m, in \u001b[0;36mKaggleDataExtractor.extract\u001b[0;34m(self, dest, force)\u001b[0m\n\u001b[1;32m     45\u001b[0m KaggleDatasetDownloader(dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset)\u001b[38;5;241m.\u001b[39mdownload(dest\u001b[38;5;241m=\u001b[39mzip_filepath, force\u001b[38;5;241m=\u001b[39mforce)\n\u001b[1;32m     46\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting dataset into: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdest\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 47\u001b[0m \u001b[43mKaggleZipDecompressor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzip_filepath\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monly_from\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munpack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset succesfully extracted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Workspaces/hudsonmendes-estudos/cm3070-fp/src/hlm12erc/etl/domain/kaggle_zip_decompressor.py:54\u001b[0m, in \u001b[0;36mKaggleZipDecompressor.unpack\u001b[0;34m(self, dest, force)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_destination_is_clean(dest, force)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# if force OR if the destination folder does not exist\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# extracts the data into the destination folder\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m zipfh:\n\u001b[1;32m     55\u001b[0m     filenames \u001b[38;5;241m=\u001b[39m zipfh\u001b[38;5;241m.\u001b[39mnamelist()\n\u001b[1;32m     56\u001b[0m     filecount \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(filenames)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/zipfile.py:1251\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1251\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilemode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m   1253\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/tmp/hlm12erc/etl/zaber666-meld-dataset/extractor/zaber666-meld-dataset'"
     ]
    }
   ],
   "source": [
    "from hlm12erc.etl import ETL, KaggleDataset\n",
    "\n",
    "ds_kaggle = KaggleDataset(owner=\"zaber666\", name=\"meld-dataset\", subdir=\"MELD-RAW/MELD.Raw\")\n",
    "etl = ETL(dataset=ds_kaggle).into(uri_or_folderpath=dir_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {str(dir_data)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2. [T]ransformation (Data Cleaning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed 1,60d $folderpath_dataset/README.txt | head -n 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(folderpath_dataset / \"train/train_sent_emo.csv\")\n",
    "df = df.loc[(df.Season == 6) & (df.Episode == 25)]\n",
    "df = df.sort_values(by=[\"StartTime\", \"EndTime\"])\n",
    "df = df[[\"Speaker\", \"Utterance\", \"Emotion\", \"Sentiment\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2. [L]oading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Statistical Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1. Measures of Spread\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2. Types of Distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Data Visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1. Word Cloud & Frequency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2. Image Grid & Scatter Plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.3. Audio Feature Plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Machine Learning\n",
    "\n",
    "**Universal Machine-learning Workflow**[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Problem Definition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Measure of Success\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Evaluation Protocol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Data Preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Baseline Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6. Overfitting Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7. Model Tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Chollet, François. Deep Learning with Python. Manning, 2017.\n",
    "\n",
    "[2] Poria, Soujanya, et al. ‘MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversations’. ArXiv [Cs.CL], 2019, http://arxiv.org/abs/1810.02508. arXiv.\n",
    "\n",
    "[3] Chen, Sheng-Yeh, et al. ‘EmotionLines: An Emotion Corpus of Multi-Party Conversations’. ArXiv [Cs.CL], 2018, http://arxiv.org/abs/1802.08379. arXiv.\n",
    "\n",
    "[4] Su, Lin, et al. ‘GEM: A General Evaluation Benchmark for Multimodal Tasks’. ArXiv [Cs.CL], 2021, http://arxiv.org/abs/2106.09889. arXiv.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
